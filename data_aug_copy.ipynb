{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# data analysis imports\n",
    "import pymysql as msql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pdb\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tables\n",
    "------\n",
    "cb_acquisitions\n",
    "cb_degrees\n",
    "cb_funding_rounds\n",
    "cb_funds\n",
    "cb_ipos\n",
    "cb_milestones\n",
    "cb_objects\n",
    "cb_offices\n",
    "cb_people\n",
    "cb_relationships\n",
    "cb_investments\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def establish_connection():\n",
    "    \"\"\"\n",
    "        Helper to establish connection with local mysql database. Returns cursor object. Publicly available\n",
    "        dataset so password commits are ignored.\n",
    "    \"\"\"\n",
    "    conn = msql.connect(host=\"localhost\", user=\"root\", password=\"startupmi\", db=\"startupmi\", \n",
    "                        cursorclass=msql.cursors.DictCursor)\n",
    "    return conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_dataframe(cursor):\n",
    "    \"\"\"\n",
    "        Helper to fetch from database and return pandas dataframe.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        cursor : {pymysql.connection.cursor}\n",
    "            primary cursor obj\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification(estimator, X, y, n_folds=10, name=\"\"):\n",
    "    \"\"\"\n",
    "        Helper to run classification with arbitrary estimator.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator : {sklearn.*}\n",
    "            scikit learn estimator - e.g. RandomForestClassifier, GaussianNB\n",
    "        \n",
    "        X : {numpy.array}\n",
    "            full feature set to be split into train/test\n",
    "        \n",
    "        y : {numpy.array}\n",
    "            target set\n",
    "        \n",
    "        n_folds : {int}\n",
    "            number of folds for stratified shuffle split\n",
    "        \n",
    "        name : {str}\n",
    "            estimator name\n",
    "    \"\"\"\n",
    "    if n_folds < 2:\n",
    "        print \"lower bound of 2 splits...\"\n",
    "        return None\n",
    "    \n",
    "    predicted = cross_val_predict(estimator, X, y, cv=n_folds, verbose=2)\n",
    "    \n",
    "    report_title = \"Classification Report for %s With Cross Validation\" % name\n",
    "    \n",
    "    print \"\\n\"\n",
    "    print report_title\n",
    "    print \"-\"*len(report_title)\n",
    "    print \"\\n\"\n",
    "    \n",
    "    print classification_report(y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "Create dataframes for all of the db tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crs = establish_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crs.execute(\"select * from cb_acquisitions\")\n",
    "df_acquisitions = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_degrees\")\n",
    "df_degrees = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_funding_rounds\")\n",
    "df_funrnds = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_funds\")\n",
    "df_funds = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_investments_1\")\n",
    "df_investments = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_ipos\")\n",
    "df_ipos = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_milestones\")\n",
    "df_milestones = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_objects\")\n",
    "df_objects = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_offices\")\n",
    "df_offices = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_people\")\n",
    "df_people = fetch_dataframe(crs)\n",
    "\n",
    "crs.execute(\"select * from cb_relationships\")\n",
    "df_relationships = fetch_dataframe(crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking Up Objects Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_companies = df_objects.loc[df_objects['entity_type']=='Company']\n",
    "df_closed_companies = df_all_companies.loc[df_all_companies['status']=='closed']\n",
    "\n",
    "df_acquired_companies = df_all_companies.loc[df_all_companies['status']=='acquired']\n",
    "df_ipo_companies = df_all_companies.loc[df_all_companies['status']=='ipo']\n",
    "\n",
    "frames = [df_closed_companies, df_acquired_companies, df_ipo_companies]\n",
    "df_relevant_companies = pd.concat(frames)\n",
    "\n",
    "df_fin_orgs = df_objects.loc[df_objects['entity_type']=='FinancialOrg']\n",
    "df_people = df_objects.loc[df_objects['entity_type']=='Person']\n",
    "\n",
    "# don't use df_objects anymore, use one of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for table consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that df_acquired_companies matches up perfectly with df_acquisitions\n",
    "\n",
    "df_acquired_tings = df_all_companies.loc[df_all_companies['id'].isin(df_acquisitions.acquired_object_id)]\n",
    "\n",
    "# should be empty set\n",
    "print np.setdiff1d(df_acquired_tings.id, df_acquired_companies.id)\n",
    "\n",
    "# should also be empty but isn't for some reason..\n",
    "# probably because those rows were deleted in Objects but not in Acquisitions\n",
    "print np.setdiff1d(df_acquisitions.acquired_object_id, df_acquired_tings.id)\n",
    "deleted_companies = np.setdiff1d(df_acquisitions.acquired_object_id, df_acquired_tings.id)\n",
    "\n",
    "# should be all False\n",
    "print np.in1d(deleted_companies, df_acquired_companies.id)\n",
    "\n",
    "# so we can go ahead and delete these from df_acquisitions\n",
    "acq_companies = np.setdiff1d(df_acquisitions.acquired_object_id, deleted_companies)\n",
    "df_acquisitions = df_acquisitions[df_acquisitions.acquired_object_id.isin(acq_companies)]\n",
    "\n",
    "# should be empty now--so we good\n",
    "print np.setdiff1d(df_acquisitions.acquired_object_id, df_acquired_tings.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same checks for ipo companies\n",
    "df_ipo_tings = df_all_companies.loc[df_all_companies['id'].isin(df_ipos.object_id.unique())]\n",
    "\n",
    "# should be empty but is not\n",
    "print np.setdiff1d(df_ipo_tings.id, df_ipo_companies.id)\n",
    "# df_ipo_tings is bigger\n",
    "print df_ipo_tings.shape, df_ipo_companies.shape\n",
    "# this is because some companies that have been acquired have gone public\n",
    "# under their own name (not their acquirers name)\n",
    "# so we should prbly just take df_ipo_tings as our list of ipo_companies\n",
    "df_ipo_companies = df_ipo_tings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "Apply transformations to each of the transformations for dtype compatibility. Create additional dataframes where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acquisition_transform(df):\n",
    "    \"\"\"\n",
    "        Method to transform acquisition dataframe for compatibility with remaining data set.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "            acquisitons dataframe\n",
    "    \"\"\"\n",
    "    # we trust master source (crunchbase) and we're not scraping source data\n",
    "    # uninterested in creation/update dates\n",
    "    drop_cols = [\"source_url\", \"source_description\", \"created_at\", \"updated_at\"]\n",
    "    for col in drop_cols:\n",
    "        df.drop(col, inplace=True, axis=1)\n",
    "    \n",
    "    # convert all decimal values to float for sklearn compatibility\n",
    "    decimal_cols = [\"price_amount\"]\n",
    "    for col in decimal_cols:\n",
    "        df[col] = df[col].apply(lambda x: float(x) if x is not None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acquisition_transform(df_acquisitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def degrees_transform(df, subject_ohe=False):\n",
    "    \"\"\"\n",
    "        Method to transform degrees dataframe. All transformations are conducted on original dataframe.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "            degrees dataframe\n",
    "        \n",
    "        subject_ohe : {bool}\n",
    "            one hot encode subjects. default to False as degree subject might not necessarily be\n",
    "            strong indicator of people success.\n",
    "    \"\"\"\n",
    "    # uninterested in creation and update dates\n",
    "    drop_cols = [\"created_at\", \"updated_at\"]\n",
    "    for col in drop_cols:\n",
    "        df.drop(col, inplace=True, axis=1)\n",
    "    \n",
    "    # significant date ranges for features\n",
    "    \n",
    "    df_degrees[\"subject\"] = \\\n",
    "            df_degrees[\"subject\"].apply(lambda x: [sub.strip() for sub in x.split(\",\")] if x is not None else [])\n",
    "    \n",
    "    if subject_ohe:\n",
    "        # binary features for subjects (multiple subjects are grouped together)\n",
    "        subject_store = set(sum(df_degrees.subject.tolist(), []))\n",
    "\n",
    "        # OHE for each subject\n",
    "        for subj in subject_store:\n",
    "            df[\"is_%s\" % subj] = df[\"subject\"].apply(lambda x: 1 if subj in x else 0)\n",
    "\n",
    "        df.drop(\"subject\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees_transform(df_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def funds_transform(df):\n",
    "    drop_cols = [\"created_at\", \"updated_at\", \"source_description\", \"source_url\"]\n",
    "    for col in drop_cols:\n",
    "        df.drop(col, inplace=True, axis=1)\n",
    "    \n",
    "    decimal_cols = [\"raised_amount\"]\n",
    "    for col in decimal_cols:\n",
    "        df[col] = df[col].apply(lambda x: float(x) if x is not None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "funds_transform(df_funds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_by</th>\n",
       "      <th>funded_at</th>\n",
       "      <th>funding_round_code</th>\n",
       "      <th>funding_round_id</th>\n",
       "      <th>funding_round_type</th>\n",
       "      <th>id</th>\n",
       "      <th>is_first_round</th>\n",
       "      <th>is_last_round</th>\n",
       "      <th>object_id</th>\n",
       "      <th>...</th>\n",
       "      <th>post_money_valuation_usd</th>\n",
       "      <th>pre_money_currency_code</th>\n",
       "      <th>pre_money_valuation</th>\n",
       "      <th>pre_money_valuation_usd</th>\n",
       "      <th>raised_amount</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>raised_currency_code</th>\n",
       "      <th>source_description</th>\n",
       "      <th>source_url</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-07-04 04:52:57</td>\n",
       "      <td>initial-importer</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>series-b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c:4</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8500000</td>\n",
       "      <td>8500000</td>\n",
       "      <td>USD</td>\n",
       "      <td>None</td>\n",
       "      <td>http://www.marketingvox.com/archives/2006/12/2...</td>\n",
       "      <td>2008-02-27 23:14:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-05-27 06:08:18</td>\n",
       "      <td>initial-importer</td>\n",
       "      <td>2004-09-01</td>\n",
       "      <td>angel</td>\n",
       "      <td>2</td>\n",
       "      <td>angel</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c:5</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>USD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>500000</td>\n",
       "      <td>500000</td>\n",
       "      <td>USD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-06-28 20:07:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at        created_by   funded_at funding_round_code  \\\n",
       "0 2007-07-04 04:52:57  initial-importer  2006-12-01                  b   \n",
       "1 2007-05-27 06:08:18  initial-importer  2004-09-01              angel   \n",
       "\n",
       "   funding_round_id funding_round_type  id  is_first_round  is_last_round  \\\n",
       "0                 1           series-b   1               0              0   \n",
       "1                 2              angel   2               0              1   \n",
       "\n",
       "  object_id         ...          post_money_valuation_usd  \\\n",
       "0       c:4         ...                              None   \n",
       "1       c:5         ...                              None   \n",
       "\n",
       "  pre_money_currency_code pre_money_valuation pre_money_valuation_usd  \\\n",
       "0                    None                None                    None   \n",
       "1                     USD                None                    None   \n",
       "\n",
       "  raised_amount raised_amount_usd raised_currency_code source_description  \\\n",
       "0       8500000           8500000                  USD               None   \n",
       "1        500000            500000                  USD               None   \n",
       "\n",
       "                                          source_url          updated_at  \n",
       "0  http://www.marketingvox.com/archives/2006/12/2... 2008-02-27 23:14:29  \n",
       "1                                               None 2013-06-28 20:07:23  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_funrnds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([              u'created_at',               u'created_by',\n",
       "                      u'funded_at',       u'funding_round_code',\n",
       "               u'funding_round_id',       u'funding_round_type',\n",
       "                             u'id',           u'is_first_round',\n",
       "                  u'is_last_round',                u'object_id',\n",
       "                   u'participants', u'post_money_currency_code',\n",
       "           u'post_money_valuation', u'post_money_valuation_usd',\n",
       "        u'pre_money_currency_code',      u'pre_money_valuation',\n",
       "        u'pre_money_valuation_usd',            u'raised_amount',\n",
       "              u'raised_amount_usd',     u'raised_currency_code',\n",
       "             u'source_description',               u'source_url',\n",
       "                     u'updated_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_funrnds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empty_funds = df_company[df_company.funding_total_usd.apply(lambda x: x is None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddhanthunnithan/.virtualenvs/document_classification/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "empty_funds[\"object_id\"] = empty_funds[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id_1</th>\n",
       "      <th>name</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>funding_rounds</th>\n",
       "      <th>object_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [object_id_1, name, funding_total_usd, funding_rounds, object_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_funds[[\"object_id\", \"name\", \"funding_total_usd\", \"funding_rounds\"]].join(\n",
    "    df_funds[[\"object_id\"]], on=\"object_id\", how=\"inner\", lsuffix=\"_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_company = df_objects[(df_objects.status != \"operating\") & (df_objects.entity_type == \"Company\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddhanthunnithan/.virtualenvs/document_classification/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# store names for future reference\n",
    "name_index = df_company[[\"id\", \"normalized_name\"]]\n",
    "df_company.drop(\"normalized_name\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_cols = [\"entity_type\", \"description\", \"first_milestone_at\", \"logo_url\", \"parent_id\", \"updated_at\",\n",
    "                 \"created_at\", \"homepage_url\", \"investment_rounds\", \"last_milestone_at\",\n",
    "                 \"logo_width\", \"permalink\", \"short_description\", \"closed_at\", \"created_by\", \"entity_id\", \"logo_height\",\n",
    "                 \"twitter_username\", \"name\", \"domain\"]\n",
    "df_company_mod = df_company.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      u'category_code',                u'city',        u'country_code',\n",
       "          u'first_funding_at', u'first_investment_at',          u'founded_at',\n",
       "            u'funding_rounds',   u'funding_total_usd',                  u'id',\n",
       "        u'invested_companies',     u'last_funding_at',  u'last_investment_at',\n",
       "                u'milestones',            u'overview',              u'region',\n",
       "             u'relationships',          u'state_code',              u'status',\n",
       "                  u'tag_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_company_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_investments[\"investor_class\"] = df_investments.investor_object_id.apply(lambda x: x.split(\":\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map investor class to new col in company df\n",
    "inv_class_map = {\"c\":\"num_comp_investors\", \"f\":\"num_fin_investors\", \"p\":\"num_ppl_investors\"}\n",
    "\n",
    "for cls in inv_class_map:\n",
    "    inter_count = pd.DataFrame(\n",
    "        df_investments[df_investments.investor_class == cls].groupby(\"funded_object_id\").count()[\"investor_object_id\"]).reset_index()\n",
    "    inter_count.columns = [\"object_id\", inv_class_map[cls]]\n",
    "    df_company_mod = df_company_mod.merge(inter_count, left_on=\"id\", right_on=\"object_id\", how=\"left\")\n",
    "    df_company_mod.drop(\"object_id\", inplace=True, axis=1)\n",
    "    \n",
    "    # assign 0 for companies with 0 count\n",
    "    df_company_mod[inv_class_map[cls]] = df_company_mod[inv_class_map[cls]].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "\n",
    "df_company_mod[\"total_investors\"] = \\\n",
    "    df_company_mod[\"num_comp_investors\"] + df_company_mod[\"num_fin_investors\"] + df_company_mod[\"num_ppl_investors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_code</th>\n",
       "      <th>city</th>\n",
       "      <th>country_code</th>\n",
       "      <th>first_funding_at</th>\n",
       "      <th>first_investment_at</th>\n",
       "      <th>founded_at</th>\n",
       "      <th>funding_rounds</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>id</th>\n",
       "      <th>invested_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>overview</th>\n",
       "      <th>region</th>\n",
       "      <th>relationships</th>\n",
       "      <th>state_code</th>\n",
       "      <th>status</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>num_ppl_investors</th>\n",
       "      <th>num_comp_investors</th>\n",
       "      <th>num_fin_investors</th>\n",
       "      <th>total_investors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>games_video</td>\n",
       "      <td>Culver City</td>\n",
       "      <td>USA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>c:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flektor is a rich-media mash-up platform that ...</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>6</td>\n",
       "      <td>CA</td>\n",
       "      <td>acquired</td>\n",
       "      <td>flektor, photo, video</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>games_video</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>USA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>c:100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>There.com is an online virtual world where any...</td>\n",
       "      <td>SF Bay</td>\n",
       "      <td>12</td>\n",
       "      <td>CA</td>\n",
       "      <td>acquired</td>\n",
       "      <td>virtualworld, there, teens</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>web</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>USA</td>\n",
       "      <td>2008-02-26</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>5000000</td>\n",
       "      <td>c:1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[FriendFeed](http://www.friendfeed.com) aims t...</td>\n",
       "      <td>SF Bay</td>\n",
       "      <td>14</td>\n",
       "      <td>CA</td>\n",
       "      <td>acquired</td>\n",
       "      <td>socialnetwork, newsfeed, socialnetworkaggregator</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>games_video</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-08-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>c:10012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>moviestring.com provides a place for user to c...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>closed</td>\n",
       "      <td>movies, micro-reviews, micro-blogging</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobile</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>USA</td>\n",
       "      <td>2008-09-01</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>c:10014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobclix (www.mobclix.com) is the industry's la...</td>\n",
       "      <td>SF Bay</td>\n",
       "      <td>9</td>\n",
       "      <td>CA</td>\n",
       "      <td>acquired</td>\n",
       "      <td>techcrunch50, tc50, iphone, analytics, free-de...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  category_code           city country_code first_funding_at  \\\n",
       "0   games_video    Culver City          USA             None   \n",
       "1   games_video      San Mateo          USA             None   \n",
       "2           web  Mountain View          USA       2008-02-26   \n",
       "3   games_video           None         None             None   \n",
       "4        mobile      Palo Alto          USA       2008-09-01   \n",
       "\n",
       "  first_investment_at  founded_at  funding_rounds funding_total_usd       id  \\\n",
       "0                None        None             NaN              None     c:10   \n",
       "1                None        None             NaN              None    c:100   \n",
       "2                None  2007-10-01               1           5000000   c:1001   \n",
       "3                None  2008-08-22             NaN              None  c:10012   \n",
       "4                None  2008-03-01               1              None  c:10014   \n",
       "\n",
       "   invested_companies       ...         \\\n",
       "0                 NaN       ...          \n",
       "1                 NaN       ...          \n",
       "2                 NaN       ...          \n",
       "3                 NaN       ...          \n",
       "4                 NaN       ...          \n",
       "\n",
       "                                            overview       region  \\\n",
       "0  Flektor is a rich-media mash-up platform that ...  Los Angeles   \n",
       "1  There.com is an online virtual world where any...       SF Bay   \n",
       "2  [FriendFeed](http://www.friendfeed.com) aims t...       SF Bay   \n",
       "3  moviestring.com provides a place for user to c...      unknown   \n",
       "4  Mobclix (www.mobclix.com) is the industry's la...       SF Bay   \n",
       "\n",
       "   relationships state_code    status  \\\n",
       "0              6         CA  acquired   \n",
       "1             12         CA  acquired   \n",
       "2             14         CA  acquired   \n",
       "3              1       None    closed   \n",
       "4              9         CA  acquired   \n",
       "\n",
       "                                            tag_list num_ppl_investors  \\\n",
       "0                              flektor, photo, video                 0   \n",
       "1                         virtualworld, there, teens                 0   \n",
       "2   socialnetwork, newsfeed, socialnetworkaggregator                 2   \n",
       "3              movies, micro-reviews, micro-blogging                 0   \n",
       "4  techcrunch50, tc50, iphone, analytics, free-de...                 0   \n",
       "\n",
       "  num_comp_investors num_fin_investors  total_investors  \n",
       "0                  0                 0                0  \n",
       "1                  0                 0                0  \n",
       "2                  0                 1                3  \n",
       "3                  0                 0                0  \n",
       "4                  1                 0                1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_company_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# null values across all columns\n",
    "nan_count = pd.DataFrame(df_company_mod.isnull().sum())\n",
    "nan_count.columns = [\"nan_count\"]\n",
    "nan_count = nan_count.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_code</th>\n",
       "      <th>city</th>\n",
       "      <th>country_code</th>\n",
       "      <th>first_funding_at</th>\n",
       "      <th>first_investment_at</th>\n",
       "      <th>founded_at</th>\n",
       "      <th>funding_rounds</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>id</th>\n",
       "      <th>invested_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>overview</th>\n",
       "      <th>region</th>\n",
       "      <th>relationships</th>\n",
       "      <th>state_code</th>\n",
       "      <th>status</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>num_ppl_investors</th>\n",
       "      <th>num_comp_investors</th>\n",
       "      <th>num_fin_investors</th>\n",
       "      <th>total_investors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nan_count</th>\n",
       "      <td>2991</td>\n",
       "      <td>3662</td>\n",
       "      <td>3256</td>\n",
       "      <td>8013</td>\n",
       "      <td>12775</td>\n",
       "      <td>5728</td>\n",
       "      <td>7940</td>\n",
       "      <td>8549</td>\n",
       "      <td>0</td>\n",
       "      <td>12774</td>\n",
       "      <td>...</td>\n",
       "      <td>1074</td>\n",
       "      <td>0</td>\n",
       "      <td>4658</td>\n",
       "      <td>6008</td>\n",
       "      <td>0</td>\n",
       "      <td>2394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category_code  city  country_code  first_funding_at  \\\n",
       "nan_count           2991  3662          3256              8013   \n",
       "\n",
       "           first_investment_at  founded_at  funding_rounds  funding_total_usd  \\\n",
       "nan_count                12775        5728            7940               8549   \n",
       "\n",
       "           id  invested_companies       ...         overview  region  \\\n",
       "nan_count   0               12774       ...             1074       0   \n",
       "\n",
       "           relationships  state_code  status  tag_list  num_ppl_investors  \\\n",
       "nan_count           4658        6008       0      2394                  0   \n",
       "\n",
       "           num_comp_investors  num_fin_investors  total_investors  \n",
       "nan_count                   0                  0                0  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delta_cols(dt_1, dt_2):\n",
    "    \"\"\"\n",
    "        Compute days delta for date/time columns.\n",
    "    \"\"\"\n",
    "    if dt_1 is None or dt_2 is None:\n",
    "        return np.nan\n",
    "    return (dt_2 - dt_1).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temporal features\n",
    "td_dt = dt.date.today()\n",
    "\n",
    "df_company_mod[\"age\"] = df_company_mod.apply(lambda x: delta_cols(x[\"founded_at\"], td_dt), axis=1)\n",
    "\n",
    "df_company_mod[\"delta_funding\"] = df_company_mod.apply(lambda x: delta_cols(x[\"last_funding_at\"], x[\"first_funding_at\"]),axis=1)\n",
    "\n",
    "# skip investments for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean continuous cols\n",
    "df_company_mod[\"funding_rounds\"] = df_company_mod[\"funding_rounds\"].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "\n",
    "df_company_mod[\"funding_total_usd\"] = df_company_mod[\"funding_total_usd\"].apply(lambda x: 0.0 if x is None else x)\n",
    "\n",
    "df_company_mod[\"milestones\"] = df_company_mod[\"milestones\"].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "\n",
    "df_company_mod[\"invested_companies\"] = df_company_mod[\"invested_companies\"].apply(lambda x: 0 if np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_company_mod[\"success\"] = df_company_mod[\"status\"].apply(lambda x: 1 if x == \"acquired\" or x == \"ipo\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature - number of successes (ipo or acquisition) across all investors\n",
    "\n",
    "inv_cls_map = {\"f\": \"fin_inv_successes\", \"c\": \"comp_inv_successes\", \"p\": \"ppl_inv_successes\"}\n",
    "\n",
    "for cls, colnm in inv_cls_map.iteritems():\n",
    "    # group by investor id and funded object id\n",
    "    inv_cls_filt = df_investments[df_investments.investor_class == cls]\n",
    "\n",
    "    inv_fnd_grp = inv_cls_filt.groupby([\"investor_object_id\", \"funded_object_id\"]).count()\n",
    "    old_cols = inv_fnd_grp.columns\n",
    "    inv_fnd_grp = inv_fnd_grp.reset_index()\n",
    "    inv_fnd_grp.columns = [\"investor_id\", \"object_id\"] + [col for col in old_cols]\n",
    "    inv_fnd_grp.drop(old_cols, axis=1, inplace=True)\n",
    "\n",
    "    # label funded objects as successful\n",
    "    inv_fnd_grp = inv_fnd_grp.merge(df_company_mod[[\"id\",\"success\"]], left_on=\"object_id\", right_on=\"id\", how=\"inner\")\n",
    "\n",
    "    # group by investor id and sum successes\n",
    "    inv_fnd_grp = inv_fnd_grp.groupby(\"investor_id\").sum()[\"success\"].reset_index()\n",
    "    inv_fnd_grp.columns = [\"investor_id\", \"num_success\"]\n",
    "\n",
    "    # group investments by funded companies\n",
    "    fnd_inv_grp = inv_cls_filt.groupby([\"funded_object_id\", \"investor_object_id\"]).count()\n",
    "    old_cols = fnd_inv_grp.columns\n",
    "    fnd_inv_grp = fnd_inv_grp.reset_index()\n",
    "    fnd_inv_grp.columns = [\"object_id\", \"investor_id\"] + [col for col in old_cols]\n",
    "    fnd_inv_grp.drop(old_cols, axis=1, inplace=True)\n",
    "\n",
    "    # merge with investor-success group\n",
    "    fnd_inv_grp = fnd_inv_grp.merge(inv_fnd_grp, on=\"investor_id\", how=\"inner\")\n",
    "\n",
    "    # group by funded companies and sum\n",
    "    fnd_inv_grp = fnd_inv_grp.groupby(\"object_id\").sum()[\"num_success\"].reset_index()\n",
    "    fnd_inv_grp.columns = [\"object_id\", colnm]\n",
    "    \n",
    "    df_company_mod = df_company_mod.merge(fnd_inv_grp, left_on=\"id\", right_on = \"object_id\", how=\"left\")\n",
    "    df_company_mod.drop(\"object_id\", inplace=True, axis=1)\n",
    "\n",
    "    # fill nan values\n",
    "    df_company_mod[colnm] = df_company_mod[colnm].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "    \n",
    "# compute total number of successes across all types of investors\n",
    "df_company_mod[\"total_investor_successes\"] = \\\n",
    "    df_company_mod[\"fin_inv_successes\"] + df_company_mod[\"comp_inv_successes\"] + df_company_mod[\"ppl_inv_successes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encoding_helper(x):\n",
    "    try:\n",
    "        x.encode(\"utf-8\")\n",
    "    except:\n",
    "        x = x.decode(\"latin-1\")\n",
    "        x = x.encode(\"utf-8\")\n",
    "    \n",
    "    return x\n",
    "\n",
    "df_company_mod[\"overview\"] = df_company_mod[\"overview\"].apply(lambda x: x if type(x) == str else \"\")\n",
    "df_company_mod[\"overview\"] = df_company_mod[\"overview\"].apply(lambda x: encoding_helper(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# topic features from overview (no topic binning)\n",
    "v = TfidfVectorizer(stop_words=\"english\")\n",
    "ov_x = v.fit_transform(df_company_mod[\"overview\"])\n",
    "ov_x = ov_x.toarray()\n",
    "ov_feats = pd.DataFrame(ov_x, columns=v.get_feature_names())\n",
    "ov_feats = ov_feats.reset_index()\n",
    "df_comp_ov = df_company_mod.reset_index()\n",
    "df_comp_ov = df_comp_ov.merge(ov_feats, on=\"index\", how=\"inner\")\n",
    "df_comp_ov.drop(\"index\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# board member labels\n",
    "df_relationships[\"on_board\"] = df_relationships[\"title\"].apply(lambda x: \"board\" in x.lower())\n",
    "df_board = df_relationships[df_relationships[\"on_board\"]]\n",
    "df_board = df_board.groupby([\"relationship_object_id\", \"on_board\"]).count()[\"person_object_id\"]\n",
    "df_board = df_board.reset_index()\n",
    "df_board.drop(\"on_board\",inplace=True,axis=1)\n",
    "df_board.columns = [\"object_id\", \"num_board_members\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# board members\n",
    "df_company_mod = df_company_mod.merge(df_board, left_on=\"id\", right_on=\"object_id\", how=\"left\")\n",
    "df_company_mod.drop(\"object_id\", inplace=True, axis=1)\n",
    "\n",
    "# large number of companies without recorded board members - 10630\n",
    "# set num board members to 0\n",
    "df_company_mod[\"num_board_members\"] = df_company_mod[\"num_board_members\"].apply(lambda x: 0 if np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>object_id</th>\n",
       "      <th>funded_at</th>\n",
       "      <th>raised_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>c:1</td>\n",
       "      <td>2005-10-01</td>\n",
       "      <td>5250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>c:1</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>9500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c:1</td>\n",
       "      <td>2008-05-19</td>\n",
       "      <td>25000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>c:1001</td>\n",
       "      <td>2008-02-26</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>c:10014</td>\n",
       "      <td>2008-09-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index object_id   funded_at raised_amount\n",
       "0      0       c:1  2005-10-01       5250000\n",
       "1      1       c:1  2007-01-01       9500000\n",
       "2      2       c:1  2008-05-19      25000000\n",
       "3      3    c:1001  2008-02-26       5000000\n",
       "4      4   c:10014  2008-09-01             0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnrnds_obj_dt_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# feature - raised money between funding rounds\n",
    "fnrnds_obj_dt_grp = df_funrnds.sort(columns=\"funded_at\")\n",
    "fnrnds_obj_dt_grp = df_funrnds.groupby([\"object_id\", \"funded_at\"]).count()[\"id\"]\n",
    "fnrnds_obj_dt_grp = fnrnds_obj_dt_grp.reset_index()\n",
    "fnrnds_obj_dt_grp.drop(\"id\", inplace=True, axis=1)\n",
    "fnrnds_obj_dt_join = fnrnds_obj_dt_grp.merge(\n",
    "    df_funrnds[[\"object_id\", \"funded_at\", \"raised_amount\"]], how=\"inner\", on=[\"object_id\", \"funded_at\"])\n",
    "# impute values of 0 for funding rounds with no raised amounts\n",
    "fnrnds_obj_dt_join[\"raised_amount\"] = fnrnds_obj_dt_join[\"raised_amount\"].apply(lambda x: 0 if x is None else x)\n",
    "\n",
    "# create custom dictionary mapping company => [(date_1, ra_1), .., (date_n, ra_n)]\n",
    "fnrnds_dct = {}\n",
    "combined = map(lambda x: (x[1], x[3]), fnrnds_obj_dt_join.to_records())\n",
    "for obj_id, amt in combined:\n",
    "    if obj_id not in fnrnds_dct:\n",
    "        fnrnds_dct[obj_id] = [float(amt)]\n",
    "        continue\n",
    "    fnrnds_dct[obj_id].append(float(amt))\n",
    "\n",
    "# compute deltas\n",
    "fnrnds_delta = {obj_id: np.average(np.diff(amts)) for obj_id, amts in fnrnds_dct.iteritems()}\n",
    "fnrnds_delta = pd.DataFrame(zip(fnrnds_delta.keys(), fnrnds_delta.values()))\n",
    "fnrnds_delta.columns = [\"object_id\", \"avg_rsd_amt_diff\"]\n",
    "\n",
    "# single round - average is 0\n",
    "fnrnds_delta.avg_rsd_amt_diff = fnrnds_delta.avg_rsd_amt_diff.apply(lambda x: 0 if np.isnan(x) else x)\n",
    "df_company_mod = df_company_mod.merge(fnrnds_delta, left_on=\"id\", right_on=\"object_id\", how=\"left\")\n",
    "\n",
    "# feature represents 'growth' so companies with no funding have 0 'growth'\n",
    "df_company_mod[\"avg_rsd_amt_diff\"] = df_company_mod[\"avg_rsd_amt_diff\"].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "df_company_mod.drop(\"object_id\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature - time between milestones (average time to achieve milestone)\n",
    "# also want to compute time between founding and first milestone\n",
    "mlstn_obj_dt_grp = df_milestones.sort(columns=\"milestone_at\")\n",
    "mlstn_obj_dt_grp = mlstn_obj_dt_grp.groupby([\"object_id\", \"milestone_at\"]).count()[\"id\"]\n",
    "mlstn_obj_dt_grp = mlstn_obj_dt_grp.reset_index()\n",
    "mlstn_obj_dt_grp.drop(\"id\", inplace=True, axis=1)\n",
    "\n",
    "mlstn_dct = {}\n",
    "for obj_id, dt in map(lambda x: (x[1], x[2]), mlstn_obj_dt_grp.to_records()):\n",
    "    if obj_id not in mlstn_dct:\n",
    "        mlstn_dct[obj_id] = [dt]\n",
    "        continue\n",
    "    mlstn_dct[obj_id].append(dt)\n",
    "\n",
    "# compute average deltas\n",
    "mlstn_delta = {obj_id: np.average(map(lambda x: x.days, np.diff(arr))) for obj_id, arr in mlstn_dct.iteritems()}\n",
    "mlstn_delta = pd.DataFrame(zip(mlstn_delta.keys(), mlstn_delta.values()), columns=[\"object_id\", \"avg_mlstn_diff\"])\n",
    "\n",
    "# only one milestone - set to zero\n",
    "mlstn_delta[\"avg_mlstn_diff\"] = mlstn_delta[\"avg_mlstn_diff\"].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "df_company_mod = df_company_mod.merge(mlstn_delta, left_on=\"id\", right_on=\"object_id\", how=\"left\")\n",
    "\n",
    "# zero milestone growth in place of null values\n",
    "df_company_mod[\"avg_mlstn_diff\"] = df_company_mod[\"avg_mlstn_diff\"].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "df_company_mod.drop(\"object_id\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature - number of offices\n",
    "obj_office_grp = df_offices.groupby([\"object_id\"]).count()[\"office_id\"]\n",
    "obj_office_grp = obj_office_grp.reset_index()\n",
    "obj_office_grp.columns = [\"object_id\", \"num_offices\"]\n",
    "df_company_mod = df_company_mod.merge(obj_office_grp, left_on=\"id\", right_on=\"object_id\", how=\"left\")\n",
    "df_company_mod.drop(\"object_id\", inplace=True, axis=1)\n",
    "df_company_mod[\"num_offices\"] = df_company_mod[\"num_offices\"].apply(lambda x: 0 if np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up region column prior to encoding\n",
    "df_company_mod[\"region\"] = df_company_mod[\"region\"].apply(lambda x: encoding_helper(x))\n",
    "df_company_mod[\"region\"] = df_company_mod[\"region\"].apply(lambda x: x.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute missing relationship values\n",
    "df_company_mod[\"relationships\"] = df_company_mod[\"relationships\"].apply(lambda x: 0 if np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>end_at</th>\n",
       "      <th>id</th>\n",
       "      <th>is_past</th>\n",
       "      <th>person_object_id</th>\n",
       "      <th>relationship_id</th>\n",
       "      <th>relationship_object_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>start_at</th>\n",
       "      <th>title</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-05-25 07:03:54</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>p:2</td>\n",
       "      <td>1</td>\n",
       "      <td>c:1</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>Co-Founder/CEO/Board of Directors</td>\n",
       "      <td>2013-06-03 09:58:46</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-05-25 07:04:16</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>p:3</td>\n",
       "      <td>2</td>\n",
       "      <td>c:1</td>\n",
       "      <td>279242</td>\n",
       "      <td>None</td>\n",
       "      <td>VP Marketing</td>\n",
       "      <td>2010-05-21 16:31:34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at end_at  id  is_past person_object_id  relationship_id  \\\n",
       "0 2007-05-25 07:03:54   None   1        0              p:2                1   \n",
       "1 2007-05-25 07:04:16   None   2        1              p:3                2   \n",
       "\n",
       "  relationship_object_id  sequence start_at  \\\n",
       "0                    c:1         8     None   \n",
       "1                    c:1    279242     None   \n",
       "\n",
       "                               title          updated_at on_board  \n",
       "0  Co-Founder/CEO/Board of Directors 2013-06-03 09:58:46     True  \n",
       "1                       VP Marketing 2010-05-21 16:31:34    False  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relationships.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature - company reach\n",
    "\n",
    "df_relationships[\"person_cls\"] = df_relationships[\"person_object_id\"].apply(lambda x: x.split(\":\")[0])\n",
    "\n",
    "df_relationships[\"obj_cls\"] = df_relationships[\"relationship_object_id\"].apply(lambda x: x.split(\":\")[0])\n",
    "\n",
    "# group relationships by people - count companies\n",
    "ppl_comp_cnt = df_relationships[(df_relationships[\"person_cls\"] == \"p\") & (df_relationships[\"obj_cls\"] == \"c\")]\n",
    "ppl_comp_cnt = ppl_comp_cnt.groupby(\"person_object_id\").count()[\"relationship_object_id\"]\n",
    "ppl_comp_cnt = ppl_comp_cnt.reset_index()\n",
    "ppl_comp_cnt.columns = [\"person_object_id\", \"company_count\"]\n",
    "\n",
    "# group relationships by companies and people\n",
    "comp_ppl_grp = df_relationships[(df_relationships[\"person_cls\"] == \"p\") & (df_relationships[\"obj_cls\"] == \"c\")]\n",
    "comp_ppl_grp = comp_ppl_grp.groupby([\"relationship_object_id\", \"person_object_id\"]).count()[\"id\"]\n",
    "comp_ppl_grp = comp_ppl_grp.reset_index()\n",
    "comp_ppl_grp.columns = [\"object_id\", \"person_object_id\", \"id\"]\n",
    "comp_ppl_grp.drop(\"id\", inplace=True, axis=1)\n",
    "\n",
    "# merge both groups\n",
    "comp_ppl_grp = comp_ppl_grp.merge(ppl_comp_cnt, on=\"person_object_id\", how=\"inner\")\n",
    "\n",
    "# aggregate company reach\n",
    "comp_ppl_grp = comp_ppl_grp.groupby(\"object_id\").sum()[\"company_count\"]\n",
    "comp_ppl_grp = comp_ppl_grp.reset_index()\n",
    "comp_ppl_grp.columns = [\"object_id\", \"company_reach\"]\n",
    "comp_ppl_grp[\"company_reach\"] = comp_ppl_grp[\"company_reach\"].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "df_company_mod = df_company_mod.merge(comp_ppl_grp, left_on=\"id\", right_on=\"object_id\", how=\"left\")\n",
    "df_company_mod.drop(\"object_id\", inplace=True, axis=1)\n",
    "df_company_mod[\"company_reach\"] = df_company_mod[\"company_reach\"].apply(lambda x: 0 if np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set target var\n",
    "target_map = {class_var:idx for idx, class_var in enumerate(set(df_company_mod[\"status\"].tolist()))}\n",
    "df_company_mod[\"class\"] = df_company_mod[\"status\"].apply(lambda x: target_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OHE categorical columns\n",
    "\n",
    "# drop_cols = [\"state_code\", \"region\", \"city\"]\n",
    "# df_company_mod.drop(drop_cols, inplace=True, axis=1)\n",
    "\n",
    "categorical_cols = [\"category_code\", \"country_code\", \"region\"]\n",
    "# df_company_mod[\"region\"] = df_company_mod[\"region\"].apply(lambda x: encoding_helper(x))\n",
    "# df_company_mod[\"region\"] = df_company_mod[\"region\"].apply(lambda x: x.decode(\"utf-8\"))\n",
    "df_encode = pd.get_dummies(df_company_mod, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([           u'category_code',                     u'city',\n",
       "                   u'country_code',         u'first_funding_at',\n",
       "            u'first_investment_at',               u'founded_at',\n",
       "                 u'funding_rounds',        u'funding_total_usd',\n",
       "                             u'id',       u'invested_companies',\n",
       "                u'last_funding_at',       u'last_investment_at',\n",
       "                     u'milestones',                 u'overview',\n",
       "                         u'region',            u'relationships',\n",
       "                     u'state_code',                   u'status',\n",
       "                       u'tag_list',        u'num_ppl_investors',\n",
       "             u'num_comp_investors',        u'num_fin_investors',\n",
       "                u'total_investors',                      u'age',\n",
       "                  u'delta_funding',                  u'success',\n",
       "              u'ppl_inv_successes',       u'comp_inv_successes',\n",
       "              u'fin_inv_successes', u'total_investor_successes',\n",
       "              u'num_board_members',         u'avg_rsd_amt_diff',\n",
       "                 u'avg_mlstn_diff',                    u'class',\n",
       "                    u'num_offices',            u'company_reach'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_company_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "omit_features = [\"category_code\", \"city\", \"country_code\", \"first_funding_at\", \"first_investment_at\", \"founded_at\", \n",
    "                 \"id\", \"last_funding_at\", \"last_investment_at\", \"overview\", \"state_code\",\n",
    "                 \"status\", \"tag_list\", \"success\", \"class\"]\n",
    "\n",
    "# temporarily remove time-features due to volume of NaNs\n",
    "omit_features.append(\"delta_funding\") # 8013\n",
    "omit_features.append(\"age\") # 5728"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(set(df_encode.columns) - set(omit_features))\n",
    "X = df_encode[features].values\n",
    "y = df_encode[\"class\"].values\n",
    "X_train = X[:int(len(X)*0.7)]\n",
    "X_test = X[int(len(X)*0.7):]\n",
    "y_train = y[:int(len(y)*0.7)]\n",
    "y_test = y[int(len(y)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.96      0.82      2832\n",
      "          1       0.05      0.03      0.03       287\n",
      "          2       0.00      0.00      0.00       815\n",
      "\n",
      "avg / total       0.52      0.69      0.60      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# log reg\n",
    "logreg = LogisticRegression(verbose=2)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "# need to revisit class sampling - imbalanced support values\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]\n",
      "\n",
      "Classification Report for Logistic Regression With Cross Validation\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.98      0.84      9394\n",
      "          1       0.34      0.16      0.22      1134\n",
      "          2       0.00      0.00      0.00      2584\n",
      "\n",
      "avg / total       0.56      0.72      0.62     13112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "# log reg - cv\n",
    "classification(logreg, X, y, name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear svm - very slow\n",
    "lin_svc = SVC(kernel=\"linear\", verbose=True)\n",
    "lin_svc.fit(X_train, y_train)\n",
    "y_pred = lin_svc.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    3.6s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.88      2832\n",
      "          1       0.65      0.28      0.39       287\n",
      "          2       0.80      0.55      0.65       815\n",
      "\n",
      "avg / total       0.81      0.82      0.80      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, verbose=2)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    6.1s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    6.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    6.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   15.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    5.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    5.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    5.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    6.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    5.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classification Report for Random Forest With Cross Validation\n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.94      0.88      9394\n",
      "          1       0.64      0.31      0.42      1134\n",
      "          2       0.74      0.53      0.61      2584\n",
      "\n",
      "avg / total       0.79      0.80      0.78     13112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest - cv\n",
    "classification(rf, X, y, name=\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.02      0.04      2832\n",
      "          1       0.59      0.03      0.07       287\n",
      "          2       0.21      0.97      0.34       815\n",
      "\n",
      "avg / total       0.44      0.22      0.11      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# naive bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification Report for Gaussian Naive Bayes With Cross Validation\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.84      9394\n",
      "          1       0.62      0.06      0.11      1134\n",
      "          2       0.00      0.00      0.00      2584\n",
      "\n",
      "avg / total       0.57      0.72      0.61     13112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "# naive bayes - cv\n",
    "classification(nb, X, y, name=\"Gaussian Naive Bayes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
